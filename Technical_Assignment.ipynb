{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ahCkHvQrOr"
   },
   "source": [
    "<h1><center></center></h1>\n",
    "<div style=\"display: flex; justify-content: center; margin: 0 auto;\" align=\"center\">\n",
    "  <img src=\"https://myth-ai.com/wp-content/uploads/2023/05/646f153be1e56.png\" href=\"https://myth-ai.com/\" width=\"100px\" align=\"center\">\n",
    "  <h1>Technical Assignment</h1>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <h2>\n",
    "  Sketch Generation via Diffusion Models using Sequential Strokes\n",
    "  </h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/googlecreativelab/quickdraw-dataset/blob/master/preview.jpg?raw=true\">\n",
    "  <figcaption>\n",
    "    Collection of 50 million drawings across 345 categories, contributed by players of the game Quick, Draw!. Drawings were captured as timestamped vectors.\n",
    "    <i>Source: <a href=\"https://quickdraw.withgoogle.com/data/\">Quick, Draw! Dataset</a>.</i>\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this project, you are expected to implement a **conditional generative diffusion model** that learns to generate hand-drawn sketches in a **stroke-by-stroke** sequential manner. Rather than generating the entire sketch at once, your model should mimic the **sequential nature of human drawing**, producing strokes one after another in a realistic and interpretable way.\n",
    "\n",
    "You will use the [Quick, Draw!](https://quickdraw.withgoogle.com/data/) dataset released by Google, which provides timestamped vector representations of user-drawn sketches across 345 object categories.\n",
    "\n",
    "---\n",
    "\n",
    "## Brief Explanation\n",
    "\n",
    "You will design and train a **separate conditional diffusion model** for each of the following three categories:\n",
    "\n",
    "- `cat`\n",
    "- `bus`\n",
    "- `rabbit`\n",
    "\n",
    "Each model must learn to generate sketches from that category using **sequential stroke data**. That means you will build **three separate models** in total‚Äîone per category.\n",
    "\n",
    "Your implementation must be documented in a reproducible Jupyter notebook, including training steps, visualizations, and both qualitative and quantitative evaluations.\n",
    "\n",
    "- Include comprehensive documentation of your approach and design decisions.\n",
    "- Provide clear training procedures, model architecture explanations, and inference code.\n",
    "- Ensure full reproducibility (running all cells should yield consistent results with fixed random seeds).\n",
    "\n",
    "---\n",
    "\n",
    "## Data Specification\n",
    "\n",
    "The Quick, Draw! dataset includes over 50 million sketches in vector format, with each sketch consisting of multiple strokes, where each stroke is a sequence of coordinates (`x`, `y`) along with timing information.\n",
    "\n",
    "You can download the raw `.ndjson` files from the this [section](#cell-id1). The following commands will download the required categories (`cat`, `bus`, `rabbit`) into the ./data directory.\n",
    "\n",
    "**‚ö†Ô∏è Note:** If you're not using Google Colab or Kaggle, make sure you have `gsutil` installed. You can install it via pip:\n",
    "\n",
    "```bash\n",
    "pip install gsutil\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Important:** The dataset files are in [NDJSON](https://github.com/ndjson/ndjson-spec) format. Make sure to install the ndjson Python module before attempting to parse the files.\n",
    "\n",
    "```bash\n",
    "pip install ndjson\n",
    "```\n",
    "\n",
    "### Train/Test Subsets for Target Categories\n",
    "\n",
    "After downloading the dataset in the `./data` directory, extract the provided `subset.zip` file. This archive includes the predefined train/test splits for each of the three categories.\n",
    "\n",
    "```\n",
    "subset/\n",
    "‚îú‚îÄ‚îÄ cat/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "‚îú‚îÄ‚îÄ bus/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "‚îî‚îÄ‚îÄ rabbit/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "```\n",
    "\n",
    "Each `indices` file contains a JSON structure with two keys:\n",
    "\n",
    "- `\"train\"`: list of indices for training\n",
    "- `\"test\"`: list of indices for testing\n",
    "\n",
    "**‚ö†Ô∏è Important:** Strictly adhere to these predefined splits for consistent evaluation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "You must evaluate your model both **qualitatively** and **quantitatively**.\n",
    "\n",
    "### Quantitative Evaluation\n",
    "\n",
    "Use the following metrics to compare the real test set sketches with those generated by your model:\n",
    "\n",
    "- **FID (Fr√©chet Inception Distance)**\n",
    "- **KID (Kernel Inception Distance)**\n",
    "\n",
    "These metrics should be computed **separately for each category** using the sketches indexed under the `\"test\"` key in each category‚Äôs `indices.json` file.\n",
    "\n",
    "> **Final submission must include three FID and three KID scores‚Äîone pair per category.**\n",
    "\n",
    "### Qualitative Evaluation\n",
    "\n",
    "Provide visual demonstrations including:\n",
    "\n",
    "- Sample generated sketches for each category.\n",
    "- Your submission must include three animated GIFs (one per category) showing the stroke-by-stroke generation process, similar to `example.gif` file in the link.\n",
    "- Comparison between real and generated sketches.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Your submission should include the following:\n",
    "\n",
    "- A well-structured **Jupyter Notebook** that:\n",
    "  - Explains your approach and design decisions\n",
    "  - Implements the conditional diffusion model\n",
    "  - Includes training procedure and inference pipeline code\n",
    "  - Presents both qualitative and quantitative results\n",
    "  - Visual examples of generated sketches for each of the 3 categories\n",
    "  - Animated GIFs demonstrating progressive sketch generation (similar to the provided example.gif)\n",
    "  - Clearly computed FID/KID scores for each category\n",
    "- Model performance analysis across categories\n",
    "- Comparison of generated vs. real sketch characteristics\n",
    "- Discussion of limitations and potential improvements\n",
    "\n",
    "\n",
    "> üîí All visualizations must be based on sketches generated by your own model. Using samples from external sources will be considered **plagiarism** and will result in disqualification.\n",
    "\n",
    "> üîÅ The notebook must be **fully reproducible**: running all cells from top to bottom should produce the same results (assuming fixed random seed).\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "- [The Quick, Draw! Dataset](https://github.com/googlecreativelab/quickdraw-dataset)\n",
    "- [Quick, Draw! Kaggle Competition](https://www.kaggle.com/c/quickdraw-doodle-recognition/overview)\n",
    "- [Diffusion Models Overview (Lil‚ÄôLog)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n",
    "- [Ha, D., & Eck, D. (2017). A neural representation of sketch drawings. arXiv preprint arXiv:1704.03477.](https://arxiv.org/pdf/1704.03477)\n",
    "- Special thanks to M. Sung, KAIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lfaHsLNkuYB"
   },
   "source": [
    "# Download the Quick, Draw! Dataset\n",
    "\n",
    "<a name=\"cell-id1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kt2OjtIbWOAQ"
   },
   "outputs": [],
   "source": [
    "# If you're not using Colab or Kaggle, uncomment the following line:\n",
    "# !pip install gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue4Lavg4XzrP"
   },
   "outputs": [],
   "source": [
    "%pip install ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRD7IDkp3ltZ",
    "outputId": "b4c53999-19e1-4f54-dd60-93f2c6d6fd81"
   },
   "outputs": [],
   "source": [
    "%mkdir data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/cat.ndjson' ./data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/bus.ndjson' ./data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/rabbit.ndjson' ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M00-fIER2U1-"
   },
   "source": [
    "# Solution\n",
    "\n",
    "- Briefly explain why you chose the method you did.\n",
    "- Discuss the drawbacks and advantages of your chosen method.\n",
    "- Evaluate and discuss the results for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHhj6nFP2Wwi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VEme3no2Xpc"
   },
   "source": [
    "# References\n",
    "\n",
    "‚ùó Do not forget to include the references you used when filling out the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERleXF7C2Zl9"
   },
   "source": [
    "- []()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
